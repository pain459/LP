{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(tokenizer, model, input_text, max_length=128):\n",
    "    \"\"\"\n",
    "    Generates a prediction from the trained model.\n",
    "    :param tokenizer: Loaded tokenizer.\n",
    "    :param model: Loaded model.\n",
    "    :param input_text: Input text to summarize or query.\n",
    "    :param max_length: Maximum length of the generated output.\n",
    "    :return: Generated summary or answer.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    outputs = model.generate(inputs, max_length=max_length, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:25: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:25: SyntaxWarning: invalid escape sequence '\\ '\n",
      "C:\\Users\\kumar\\AppData\\Local\\Temp\\ipykernel_19012\\3493924662.py:25: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  input_text = \"\"\"Log  processing  has  become  a  critical  component  of  the  data \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model unarchived to extracted_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\src_git\\LP\\LP\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output: .  We have been using Kafka in production for some time and it is  processing hundreds of gigabytes of new data each day.\n"
     ]
    }
   ],
   "source": [
    "def unarchive_model(archive_path, extract_dir):\n",
    "    \"\"\"\n",
    "    Extracts a model archive into a directory.\n",
    "    :param archive_path: Path to the .tar.gz archive.\n",
    "    :param extract_dir: Directory to extract the model files.\n",
    "    \"\"\"\n",
    "    shutil.unpack_archive(archive_path, extract_dir)\n",
    "    print(f\"Model unarchived to {extract_dir}\")\n",
    "\n",
    "# Example usage\n",
    "unarchive_model(\"final_model_archive.tar.gz\", \"extracted_model\")\n",
    "\n",
    "# Reload the model\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "def load_model_from_extracted(extracted_dir):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(extracted_dir)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(extracted_dir)\n",
    "    return tokenizer, model\n",
    "\n",
    "# Example usage\n",
    "tokenizer, model = load_model_from_extracted(\"extracted_model\")\n",
    "\n",
    "# Test the model\n",
    "input_text = \"\"\"Log  processing  has  become  a  critical  component  of  the  data \\\n",
    "pipeline for consumer internet companies. We introduce Kafka, a \\\n",
    "distributed messaging system that we developed for collecting and \\\n",
    "delivering high volumes of log data with low latency. Our system \\\n",
    "incorporates  ideas  from  existing  log  aggregators  and  messaging \\ \n",
    "systems,  and  is  suitable  for  both  offline  and  online  message \\\n",
    "consumption.  We  made  quite  a  few  unconventional  yet  practical \\\n",
    "design choices in Kafka to make our system efficient and scalable. \\\n",
    "Our experimental results show that Kafka has superior \\\n",
    "performance  when  compared  to  two  popular  messaging  systems. \\ \n",
    "We  have  been  using  Kafka  in  production  for  some  time  and  it  is \\ \n",
    "processing hundreds of gigabytes of new data each day\"\"\"\n",
    "output = test_model(tokenizer, model, input_text)\n",
    "print(f\"Model Output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
